{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22_05_30_day12_huggingface_tutorial.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QiBqgv0ZI8M",
        "outputId": "8dea7018-aa2b-4a54-a194-adb25de7eb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 24.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "model = TFAutoModel.from_pretrained(\"<model_name>\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"<model_name>\")\n",
        "```"
      ],
      "metadata": {
        "id": "a5OJC31YbB1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer 실습"
      ],
      "metadata": {
        "id": "BlbEVuXVa7fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer"
      ],
      "metadata": {
        "id": "Hcq51k_rbm4-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-multilingual-cased\"\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TwpTs0qbzRN",
        "outputId": "a8e4b13c-ab5e-40fe-c7f2-771e62192154"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8cB4vJCcOg_",
        "outputId": "bb79d415-a416-4c49-8323-f0fb58627db8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, key in enumerate(tokenizer.get_vocab()):\n",
        "    print(key)\n",
        "    if i>20:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF57Gu0mcjJJ",
        "outputId": "de4c877d-1c18-429a-e84e-d862ba89def5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vary\n",
            "sebelumnya\n",
            "protagonist\n",
            "Dancing\n",
            "nüfusu\n",
            "ספרי\n",
            "поверхні\n",
            "состояние\n",
            "இன்\n",
            "novembril\n",
            "satu\n",
            "kỳ\n",
            "##聞\n",
            "##鲑\n",
            "географин\n",
            "##rmática\n",
            "jurul\n",
            "dog\n",
            "##stin\n",
            "төшә\n",
            "׃\n",
            "稀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"이순신은 조선 중기의 무신이다.\""
      ],
      "metadata": {
        "id": "_3UCdz5FdA9q"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN-hV8E3dWMX",
        "outputId": "f6daace9-80f2-4601-df50-9db2e3647d1c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input_text = tokenizer(text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "4_CBAtwGdaJR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in tokenized_input_text.items():\n",
        "    print(\"{} : \\n\\t{}\".format(key,value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMXAhfRXdvKg",
        "outputId": "e5618170-262c-449b-c241-a2177af9fa98"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids : \n",
            "\ttensor([[   101,   9638, 119064,  25387,  10892,  59906,   9694,  46874,   9294,\n",
            "          25387,  11925,    119,    102]])\n",
            "token_type_ids : \n",
            "\ttensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask : \n",
            "\ttensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_input_text['input_ids']) # vocab id\n",
        "print(tokenized_input_text.input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXyymTU1eOv-",
        "outputId": "ce1ea0a2-b018-43f7-a060-43257275e6da"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   101,   9638, 119064,  25387,  10892,  59906,   9694,  46874,   9294,\n",
            "          25387,  11925,    119,    102]])\n",
            "tensor([[   101,   9638, 119064,  25387,  10892,  59906,   9694,  46874,   9294,\n",
            "          25387,  11925,    119,    102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_input_text['token_type_ids']) # segment id\n",
        "print(tokenized_input_text.token_type_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqbvAg-vgSfn",
        "outputId": "942121fd-f1b6-47dc-d50f-3c004a5f30d1"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_input_text['attention_mask']) # is special token\n",
        "print(tokenized_input_text.attention_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jokQbARRlFBf",
        "outputId": "8ce07c76-ed97-4d9c-9ccb-6892541be95d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text) # ##은 앞의 토큰와 붙어있는 단어임을 알려준다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8uT8Ni5lW9B",
        "outputId": "a1f388da-d026-4bdb-efe4-0e91bf41335c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.tokenize(\"요리보고\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n1rYcPwleIy",
        "outputId": "cddbac50-78dc-4837-aece-7dc42c67fd05"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['요', '##리', '##보', '##고']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfHPlWhimIuJ",
        "outputId": "6fe64236-643b-4d4f-f856-8f5e18bd21c2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_ids = tokenizer.decode(input_ids)\n",
        "print(decoded_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piOXRDdqme2p",
        "outputId": "ccacfc40-3b8d-419f-fc93-2d471a7c2891"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 이순신은 조선 중기의 무신이다. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## option"
      ],
      "metadata": {
        "id": "uYNyZfy3mpih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.tokenize(\n",
        "    text,\n",
        "    add_special_tokens = False,\n",
        "    max_length = 5,\n",
        "    truncation = True\n",
        ")\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guY5Z2r4ngFt",
        "outputId": "e7961018-d389-40ba-e424-da96a60e0a1c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '##순', '##신', '##은', '조선']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(\n",
        "    text,\n",
        "    add_special_tokens = False,\n",
        "    max_length = 5,\n",
        "    truncation = True\n",
        ")\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9-uP9IDn0Zd",
        "outputId": "872e154d-09c3-46ba-ea35-917b985bf5b9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9638, 119064, 25387, 10892, 59906]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_ids = tokenizer.decode(input_ids)\n",
        "print(decoded_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLEe9XABoFJ8",
        "outputId": "00cee33e-7be8-45be-fe4d-477fbe1aa52e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이순신은 조선\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.pad_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhRfp0NpoM5E",
        "outputId": "f801cd21-ab51-45e9-ad62-e34b85cfe910"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFllTTsQoXmH",
        "outputId": "dd634007-7686-421d-9694-ccaf11a0346f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.tokenize(\n",
        "    text,\n",
        "    add_special_tokens = False,\n",
        "    max_length = 15,\n",
        "    padding = \"max_length\"\n",
        ")\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrQ02Dr8ob5H",
        "outputId": "5d154d8c-b8fc-4a81-a6aa-df8b2fe8bab8"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(\n",
        "    text,\n",
        "    add_special_tokens = True,\n",
        "    max_length = 15,\n",
        "    padding = \"max_length\"\n",
        ")\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_qFOLjto1C-",
        "outputId": "cd6053e7-ff0d-4b6f-a1a8-abe77477221d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_ids = tokenizer.decode(input_ids)\n",
        "print(decoded_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aQuobDzpBAA",
        "outputId": "a63c58db-645a-4b11-8d6a-cf7cef7b0fa0"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 이순신은 조선 중기의 무신이다. [SEP] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 새로운 토큰을 추가해보자!"
      ],
      "metadata": {
        "id": "NgbFim5zpVkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"깟빼뜨랑 리뿔이 뜨럽거 므리커럭이 케쇼쇼쇽 나오애쇼쇼쇼 우뤼갸갸갸 청쇼랴료다혀뚜요\""
      ],
      "metadata": {
        "id": "LcivqEdspydg"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XguK0e_yqEeo",
        "outputId": "755d9680-9eac-4315-dfb9-1ddcccd1420a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[UNK]', '리', '##뿔', '##이', '뜨', '##럽', '##거', '므', '##리', '##커', '##럭', '##이', '[UNK]', '나', '##오', '##애', '##쇼', '##쇼', '##쇼', '[UNK]', '청', '##쇼', '##랴', '##료', '##다', '##혀', '##뚜', '##요']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(text)\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA5g9nZuqMYf",
        "outputId": "ff819ead-8ea1-4f6b-b38d-cb5917569f84"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 100, 9238, 119021, 10739, 9151, 118867, 41521, 9308, 12692, 106826, 118864, 10739, 100, 8982, 28188, 119121, 119060, 119060, 119060, 100, 9751, 119060, 118862, 38688, 11903, 80579, 118841, 48549, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_ids = tokenizer.decode(input_ids)\n",
        "print(decoded_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48B1vuSEqT0L",
        "outputId": "9d3baa43-35bb-4a10-abcc-9ed324303593"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] [UNK] 리뿔이 뜨럽거 므리커럭이 [UNK] 나오애쇼쇼쇼 [UNK] 청쇼랴료다혀뚜요 [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "added_token_num = tokenizer.add_tokens([\"깟빼뜨랑\",\"케쇼쇼쇽\",\"우뤼갸갸갸\"])\n",
        "print(added_token_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwWovmIfqb8s",
        "outputId": "74a832de-dfd0-40cf-ba07-69e9e609420b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygGRxXDirzP7",
        "outputId": "b872d7a4-d21c-42bc-92ee-45755195d079"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['깟빼뜨랑', '리', '##뿔', '##이', '뜨', '##럽', '##거', '므', '##리', '##커', '##럭', '##이', '케쇼쇼쇽', '나', '##오', '##애', '##쇼', '##쇼', '##쇼', '우뤼갸갸갸', '청', '##쇼', '##랴', '##료', '##다', '##혀', '##뚜', '##요']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"[mujun]이순신은 조선 중기의 무신이다.[/mujun]\"\n",
        "\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text)\n",
        "\n",
        "input_ids = tokenizer.encode(text)\n",
        "print(input_ids)\n",
        "\n",
        "decoded_ids = tokenizer.decode(input_ids)\n",
        "print(decoded_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WDpI3uMsQV4",
        "outputId": "a1dd87ec-2bea-4e12-86b8-602a2d01f162"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'mu', '##jun', ']', '이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.', '[', '/', 'mu', '##jun', ']']\n",
            "[101, 164, 12361, 46329, 166, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 164, 120, 12361, 46329, 166, 102]\n",
            "[CLS] [ mujun ] 이순신은 조선 중기의 무신이다. [ / mujun ] [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "added_token_num += tokenizer.add_special_tokens({\"additional_special_tokens\" : [\"[mujun]\",\"[/mujun]\"]})\n",
        "\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text)\n",
        "\n",
        "input_ids = tokenizer.encode(text)\n",
        "print(input_ids)\n",
        "\n",
        "decoded_ids = tokenizer.decode(input_ids)\n",
        "print(decoded_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdrJKC3wsjLv",
        "outputId": "34587e34-bb17-4129-9077-cf93edcf201c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[mujun]', '이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.', '[/mujun]']\n",
            "[101, 119550, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 119551, 102]\n",
            "[CLS] [mujun] 이순신은 조선 중기의 무신이다. [/mujun] [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single input\n",
        "single_seg_input = tokenizer(\"이순신은 조선 중기의 무신이다.\")\n",
        "\n",
        "# multiple input\n",
        "multi_seg_input = tokenizer(\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\")"
      ],
      "metadata": {
        "id": "rOAk57Las_sQ"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Single segment token(str) : {}\".format(tokenizer.convert_ids_to_tokens(single_seg_input['input_ids'])))\n",
        "print(\"Single segment token(int) : {}\".format(single_seg_input['input_ids']))\n",
        "print(\"Single segment type : {}\".format(single_seg_input['token_type_ids']))\n",
        "\n",
        "# Segments\n",
        "print()\n",
        "print(\"Single segment token(str) : {}\".format(tokenizer.convert_ids_to_tokens(multi_seg_input['input_ids'])))\n",
        "print(\"Single segment token(int) : {}\".format(multi_seg_input['input_ids']))\n",
        "print(\"Single segment type : {}\".format(multi_seg_input['token_type_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXs7gqPStuVF",
        "outputId": "be40bc6d-9eec-4744-e0a9-e9e18fcc0e0a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single segment token(str) : ['[CLS]', '이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.', '[SEP]']\n",
            "Single segment token(int) : [101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102]\n",
            "Single segment type : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Single segment token(str) : ['[CLS]', '이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.', '[SEP]', '그는', '임', '##진', '##왜', '##란', '##을', '승', '##리로', '이', '##끌', '##었다', '.', '[SEP]']\n",
            "Single segment token(int) : [101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102, 17889, 9644, 18623, 119164, 49919, 10622, 9484, 100434, 9638, 118705, 17706, 119, 102]\n",
            "Single segment type : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert 모델 테스트"
      ],
      "metadata": {
        "id": "1DwqARKUtuur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"이순신은 [MASK] 중기의 무신이다.\"\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LO2LV9dyWBb",
        "outputId": "c02da24d-e1a5-41ca-83b7-c6fe55953c01"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '##순', '##신', '##은', '[MASK]', '중', '##기의', '무', '##신', '##이다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp_fill = pipeline('fill-mask', model = model_name)\n",
        "nlp_fill(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0n9rEjay07w",
        "outputId": "09df4fa9-3b6f-49ea-91f9-ab6bdd6a3f72"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8747122883796692,\n",
              "  'sequence': '이순신은 조선 중기의 무신이다.',\n",
              "  'token': 59906,\n",
              "  'token_str': '조선'},\n",
              " {'score': 0.0643644779920578,\n",
              "  'sequence': '이순신은 청 중기의 무신이다.',\n",
              "  'token': 9751,\n",
              "  'token_str': '청'},\n",
              " {'score': 0.010954882018268108,\n",
              "  'sequence': '이순신은 전 중기의 무신이다.',\n",
              "  'token': 9665,\n",
              "  'token_str': '전'},\n",
              " {'score': 0.004647170193493366,\n",
              "  'sequence': '이순신은종 중기의 무신이다.',\n",
              "  'token': 22200,\n",
              "  'token_str': '##종'},\n",
              " {'score': 0.0036106768529862165,\n",
              "  'sequence': '이순신은기 중기의 무신이다.',\n",
              "  'token': 12310,\n",
              "  'token_str': '##기'}]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_fill(\"독도는 [MASK]의 땅이다\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHj-iM7uzHvG",
        "outputId": "016762b9-da24-4cc9-dc0b-93d3525a0126"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9185790419578552,\n",
              "  'sequence': '독도는 독 의 땅이다',\n",
              "  'token': 9088,\n",
              "  'token_str': '독'},\n",
              " {'score': 0.006001222878694534,\n",
              "  'sequence': '독도는 대한민국 의 땅이다',\n",
              "  'token': 26168,\n",
              "  'token_str': '대한민국'},\n",
              " {'score': 0.003627519588917494,\n",
              "  'sequence': '독도는 섬 의 땅이다',\n",
              "  'token': 9430,\n",
              "  'token_str': '섬'},\n",
              " {'score': 0.0032675538677722216,\n",
              "  'sequence': '독도는 일본 의 땅이다',\n",
              "  'token': 23130,\n",
              "  'token_str': '일본'},\n",
              " {'score': 0.0026966023724526167,\n",
              "  'sequence': '독도는 자 의 땅이다',\n",
              "  'token': 9651,\n",
              "  'token_str': '자'}]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_pt = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "for key, value in tokens_pt.items():\n",
        "    print(\"{} : \\n\\t{}\".format(key, value))\n",
        "\n",
        "outputs = model(**tokens_pt)\n",
        "last_hidden_state = outputs.last_hidden_state\n",
        "pooler_output = outputs.pooler_output\n",
        "\n",
        "print(\"\\nToken wise output : {}, Pooled output : {}\".format(last_hidden_state.shape, pooler_output.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inDbUsGAzZDR",
        "outputId": "12bdb5ff-d2df-4099-d271-268d55810ae5"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids : \n",
            "\ttensor([[   101,   9638, 119064,  25387,  10892,    103,   9694,  46874,   9294,\n",
            "          25387,  11925,    119,    102]])\n",
            "token_type_ids : \n",
            "\ttensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask : \n",
            "\ttensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "\n",
            "Token wise output : torch.Size([1, 13, 768]), Pooled output : torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap-ki3ga1Suz",
        "outputId": "71443ef5-d1da-4ac5-d644-aba0c34d16dc"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1990,  0.2312, -0.5632,  ...,  0.1284, -0.2287,  0.0718],\n",
              "         [ 0.1618,  0.1146, -0.0999,  ...,  0.3117,  0.3869,  0.6463],\n",
              "         [ 0.3697,  0.2132, -0.4358,  ...,  0.3572, -0.1115,  0.1626],\n",
              "         ...,\n",
              "         [ 0.1121,  0.1447, -0.1658,  ..., -0.0123, -0.0397,  0.1431],\n",
              "         [ 0.3797,  0.0343, -0.2141,  ...,  0.7549, -0.8043,  0.1917],\n",
              "         [ 0.3507,  0.1251, -0.2642,  ...,  0.0053, -0.3522,  0.3532]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooler_output # 모델의 출력결과"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTm2Vimo1myG",
        "outputId": "18a50b71-bdd1-480e-f702-0549df330fda"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.0283e-01, -1.4001e-01, -8.4018e-02, -2.6051e-01,  2.6862e-02,\n",
              "         -9.4075e-02, -1.3628e-02,  2.4797e-01, -3.0906e-01,  2.3419e-01,\n",
              "          2.2539e-02,  1.1979e-01, -3.4908e-01, -1.8756e-01,  2.4908e-01,\n",
              "          1.8911e-01,  3.4478e-01, -1.0767e-01, -2.8204e-01, -1.0324e-01,\n",
              "         -9.9910e-01, -3.2951e-01, -1.3240e-02, -2.8301e-01, -1.5239e-01,\n",
              "          1.8199e-01,  9.6231e-02,  3.9528e-01,  2.7834e-01,  9.4189e-03,\n",
              "         -7.1159e-02, -9.9930e-01,  6.5399e-01,  3.8764e-01,  3.0071e-01,\n",
              "         -3.6383e-01,  9.8969e-02,  3.0775e-01,  2.4909e-01, -4.0341e-01,\n",
              "         -5.9351e-02, -6.5761e-02,  6.4013e-02, -2.1495e-01, -2.4099e-01,\n",
              "         -3.3646e-01, -1.1709e-01,  4.1435e-01, -4.1856e-01, -2.2435e-02,\n",
              "          2.0174e-01,  2.2109e-01,  4.1770e-01, -1.0774e-01,  1.5332e-01,\n",
              "          3.7670e-01, -1.2100e-02, -2.4612e-01,  4.7919e-02, -2.9957e-01,\n",
              "         -1.9029e-01,  1.4763e-01,  7.1556e-02, -1.0966e-01,  7.7137e-04,\n",
              "         -2.8533e-01,  1.4320e-01, -2.1027e-01,  1.7116e-01, -2.2838e-01,\n",
              "         -3.9467e-01, -4.3828e-01, -2.4186e-01,  1.0229e-01,  3.3637e-01,\n",
              "         -4.3675e-01,  3.4284e-01,  1.5745e-01, -1.2196e-01,  2.1845e-02,\n",
              "         -9.8473e-02, -1.4146e-01, -4.3159e-01, -1.1549e-01, -2.0474e-01,\n",
              "          2.9396e-01, -1.9739e-01, -3.0207e-01,  7.1778e-02,  1.7703e-02,\n",
              "         -1.9229e-02,  9.4323e-02,  6.0327e-02, -9.5614e-02,  2.5036e-02,\n",
              "         -1.2916e-01, -4.1666e-01, -1.9174e-01, -2.7581e-01, -2.1998e-01,\n",
              "          1.6932e-01,  1.6810e-01, -2.2607e-01, -5.7393e-02, -4.5177e-02,\n",
              "         -1.3049e-01,  1.5557e-01,  2.1622e-01, -8.4262e-02,  2.6650e-01,\n",
              "         -2.1710e-01, -8.4952e-02, -2.3259e-01,  2.1201e-01, -2.7741e-02,\n",
              "          5.3030e-01, -1.7904e-01,  3.6174e-01, -3.9885e-01, -5.4645e-02,\n",
              "          1.1842e-01,  9.9949e-01,  6.2727e-02, -7.2407e-03,  6.5541e-02,\n",
              "          3.4774e-01, -4.1479e-01,  4.2859e-01,  1.6958e-01,  1.1810e-01,\n",
              "          1.2855e-02, -2.2827e-02, -1.0831e-01, -1.5935e-01, -4.2072e-01,\n",
              "         -1.9168e-01, -3.2768e-01,  2.1192e-01, -3.2690e-01, -1.9851e-01,\n",
              "          5.7198e-02,  2.8051e-01, -6.7867e-03, -8.7573e-02, -4.5251e-02,\n",
              "          6.7408e-02,  2.6953e-01,  7.9406e-02,  9.9914e-01,  1.6923e-01,\n",
              "         -1.3431e-01, -2.3981e-01,  5.4276e-01, -1.9379e-01, -3.2844e-04,\n",
              "         -3.4929e-01, -1.3626e-01, -1.9632e-01, -4.8871e-03,  1.7827e-01,\n",
              "          2.7154e-01, -2.8784e-01, -1.2288e-01,  4.6900e-02,  5.1364e-02,\n",
              "         -4.5997e-01, -8.5160e-02,  2.9489e-01, -3.3069e-01,  1.2745e-01,\n",
              "         -7.2761e-02,  4.2490e-01,  3.1262e-01, -6.9334e-02,  2.2934e-01,\n",
              "          2.9757e-01,  3.9397e-02, -1.3507e-01, -1.1691e-01, -8.3296e-02,\n",
              "          7.0971e-02, -1.8198e-01, -3.2296e-02, -1.7437e-01, -3.6408e-01,\n",
              "          5.7802e-03,  1.7186e-01, -1.3093e-01, -4.2321e-02,  1.3965e-01,\n",
              "         -1.7281e-01, -8.4231e-02,  8.9797e-02,  4.6394e-01,  2.2777e-01,\n",
              "          2.4167e-01, -1.4572e-01, -1.3100e-01,  2.9674e-01,  4.5927e-02,\n",
              "          5.3803e-02,  6.6704e-02,  2.1437e-01,  1.7200e-01,  7.6892e-03,\n",
              "         -5.5985e-01,  4.6642e-01,  5.5159e-02,  2.1553e-01,  1.2156e-01,\n",
              "         -1.5711e-01, -3.2584e-01,  4.7819e-02,  1.2038e-01, -2.4369e-01,\n",
              "          3.4545e-01,  4.4301e-01, -5.4281e-02, -1.7454e-01,  4.2983e-01,\n",
              "         -1.9102e-01, -2.3493e-01, -1.8686e-01, -3.8143e-01, -8.2675e-02,\n",
              "          7.8507e-02,  2.7818e-01,  2.4031e-01,  2.1540e-01, -4.5250e-02,\n",
              "         -1.0731e-01, -1.1337e-01,  3.4229e-01,  4.7835e-01,  1.1706e-01,\n",
              "          5.3497e-01,  2.2613e-02,  4.1758e-02, -1.2516e-01, -2.2842e-01,\n",
              "         -3.7695e-02, -1.1104e-01,  4.0058e-01,  4.5701e-01, -1.3478e-01,\n",
              "         -3.1973e-01, -1.2234e-01,  1.9374e-01, -3.4613e-02,  2.0468e-02,\n",
              "         -3.5415e-02, -2.4895e-01,  5.8318e-01,  1.0719e-01,  2.8779e-02,\n",
              "         -9.9942e-01,  1.7551e-01, -1.9320e-01,  2.2951e-01, -5.1420e-02,\n",
              "          3.9503e-02,  1.3919e-01,  1.6717e-01,  5.1139e-01,  7.8805e-02,\n",
              "         -3.6146e-01, -7.0342e-02, -2.7161e-01, -3.7767e-01, -2.8254e-01,\n",
              "         -1.9607e-01,  7.6305e-02,  6.0030e-02, -3.5562e-01, -1.2178e-01,\n",
              "          2.3549e-01,  9.0316e-02, -6.0627e-01,  5.6915e-01,  4.5624e-03,\n",
              "         -2.0522e-01,  1.6686e-01,  3.2760e-01, -9.9946e-01,  9.7764e-02,\n",
              "         -3.4364e-01, -3.9101e-02,  1.1379e-01,  1.8260e-01, -2.8363e-01,\n",
              "          3.0684e-01,  3.2369e-02,  2.8649e-01,  1.0563e-01,  2.8226e-01,\n",
              "          3.3204e-01, -1.7130e-01,  3.4603e-01, -8.0432e-02, -2.7560e-02,\n",
              "          4.0205e-01, -3.0880e-03,  9.4876e-02,  7.1033e-02, -2.0637e-01,\n",
              "          2.0980e-01, -4.0342e-01,  2.2334e-02,  2.8693e-01,  1.1733e-01,\n",
              "          6.9252e-02, -1.5734e-01,  1.9206e-01, -1.7538e-01,  3.2339e-01,\n",
              "         -5.4038e-02, -1.7153e-02, -1.6342e-01, -1.4867e-01,  8.4886e-02,\n",
              "         -1.6708e-01,  2.6579e-01, -2.8311e-01,  9.9944e-01,  1.9379e-01,\n",
              "          1.4070e-01, -3.0212e-01,  2.7064e-01,  6.0495e-01, -2.7581e-01,\n",
              "         -6.8814e-01, -2.0943e-01,  8.5028e-02, -6.3582e-02, -1.8746e-01,\n",
              "          3.1409e-01,  2.5680e-01,  1.5053e-01, -1.3153e-01, -4.5482e-02,\n",
              "          2.0857e-01, -1.5375e-01,  1.6801e-01, -1.0611e-01, -2.7482e-01,\n",
              "          1.6932e-01, -5.3777e-02, -4.5277e-02, -6.1108e-01, -2.5433e-01,\n",
              "          2.2789e-01,  9.7327e-02,  1.2110e-01,  6.4773e-02, -2.7568e-01,\n",
              "          2.0716e-01, -4.0791e-03, -2.5875e-01, -2.1805e-01, -9.9104e-02,\n",
              "          1.7495e-01,  3.1258e-01, -1.5024e-01, -1.2141e-01,  3.7081e-01,\n",
              "         -1.6819e-01,  2.1105e-01,  7.7881e-02, -2.7638e-01, -2.8509e-01,\n",
              "          9.6206e-02, -9.9957e-01,  2.6332e-01,  2.8642e-01, -3.7400e-01,\n",
              "          3.6665e-01, -4.5130e-02, -9.6700e-02,  1.5640e-01,  7.6099e-02,\n",
              "          1.2733e-01,  1.3089e-01, -6.4764e-02,  4.0121e-02,  1.3384e-01,\n",
              "          1.7373e-01,  5.6739e-01,  2.4243e-01,  1.1654e-01, -1.7823e-01,\n",
              "          4.6174e-01, -2.8530e-01, -1.9809e-01,  3.1568e-01,  1.6060e-01,\n",
              "          1.4076e-01, -6.9938e-02,  7.1258e-02,  7.8558e-02,  2.5798e-02,\n",
              "          2.0121e-01,  8.4302e-02, -9.2243e-02,  8.3410e-02,  1.6689e-01,\n",
              "         -2.5900e-01, -3.2082e-01,  2.4415e-01,  6.5442e-02,  3.6684e-01,\n",
              "         -1.6245e-02,  2.6123e-01,  7.7480e-03,  1.2822e-01, -4.1402e-01,\n",
              "         -1.1437e-01,  2.7102e-02,  1.8294e-02, -3.1947e-01, -3.3406e-02,\n",
              "         -1.8446e-01,  9.9928e-01,  2.6662e-01, -4.8984e-02, -2.7125e-01,\n",
              "          1.8353e-01,  1.4678e-02, -1.9103e-01,  4.3832e-01,  4.7717e-01,\n",
              "          1.4718e-01, -2.5863e-02,  1.6341e-01,  3.6073e-01,  1.2253e-01,\n",
              "          2.2675e-01,  2.7954e-01,  3.0475e-01, -3.4483e-01,  1.3079e-01,\n",
              "         -1.1885e-01, -4.0037e-01, -6.8967e-01,  1.5199e-01,  4.8567e-01,\n",
              "         -2.0685e-01, -6.7178e-01,  1.3996e-01, -3.3152e-01,  7.5027e-02,\n",
              "         -3.3100e-01,  1.6887e-01,  2.5943e-01, -2.4521e-01,  2.0278e-01,\n",
              "         -2.9481e-01,  9.9937e-01, -3.4674e-01,  1.0659e-01,  1.3321e-01,\n",
              "          2.1818e-01, -3.5593e-02, -4.0290e-01, -1.1729e-01,  2.6323e-01,\n",
              "         -1.7751e-01,  5.6408e-02, -2.6720e-01,  2.1813e-01, -4.0958e-03,\n",
              "          2.7244e-01, -2.6711e-01,  3.5452e-01,  5.3653e-02,  3.1105e-01,\n",
              "         -5.5231e-02, -8.7679e-02, -1.9587e-01,  4.7145e-02, -3.0437e-01,\n",
              "          2.5628e-01, -3.2959e-03, -1.7690e-02, -1.0061e-02,  1.3758e-01,\n",
              "          1.5115e-01,  7.1283e-02,  1.1576e-01, -1.1372e-01,  7.0157e-02,\n",
              "          5.9369e-02, -3.2402e-02,  4.1622e-01, -2.3465e-01,  9.9922e-01,\n",
              "         -1.1481e-01,  2.9802e-01, -2.2262e-01,  1.5153e-01, -6.3547e-02,\n",
              "          2.6747e-01,  2.2428e-01, -4.2495e-01,  4.8905e-02,  3.8537e-01,\n",
              "         -1.9512e-01,  2.8482e-01, -1.4379e-01, -8.3704e-01, -2.3900e-01,\n",
              "          6.5868e-01, -2.0871e-01,  1.3054e-01,  2.0880e-01,  1.3263e-01,\n",
              "          1.8448e-01,  1.8803e-03,  1.5331e-01,  4.0075e-01,  6.1553e-02,\n",
              "          1.5123e-01,  1.6876e-01,  2.5088e-01, -1.5511e-01, -4.0860e-01,\n",
              "          9.9928e-01,  9.9913e-01,  1.4469e-02,  3.3374e-01, -3.0529e-01,\n",
              "         -1.2837e-02, -4.6432e-01,  1.3612e-01, -1.1575e-01, -5.4013e-02,\n",
              "          7.3161e-02,  3.2705e-01, -8.4096e-02, -3.4410e-01, -8.8568e-02,\n",
              "          7.6503e-02, -1.8067e-03, -2.8267e-01, -2.4691e-01,  2.3304e-01,\n",
              "          1.1846e-01,  5.0607e-02,  8.7368e-02, -6.8667e-02,  2.6950e-01,\n",
              "          2.3090e-01, -2.2411e-01,  1.8560e-01, -2.0245e-01, -3.7963e-02,\n",
              "         -2.6793e-01,  2.8842e-01, -9.9938e-01,  1.8784e-02, -6.5584e-02,\n",
              "         -1.7947e-01,  4.9703e-01,  4.9550e-01,  1.0196e-01, -1.4413e-01,\n",
              "         -3.9604e-01, -2.6032e-02, -7.2411e-02, -4.1024e-02,  8.6468e-02,\n",
              "         -3.4959e-01, -2.7203e-01,  2.0034e-01, -2.7192e-02,  7.2617e-03,\n",
              "         -1.5731e-01,  3.6164e-02, -1.5472e-01, -1.9528e-01, -5.1079e-01,\n",
              "          5.7055e-01, -1.7987e-01, -4.6884e-02,  5.4158e-01, -3.6365e-02,\n",
              "         -3.0633e-02, -2.6466e-01,  3.0197e-01, -1.3478e-01,  2.0036e-01,\n",
              "         -1.7307e-01, -1.1545e-01,  1.7890e-01, -3.9799e-01, -4.6579e-01,\n",
              "         -7.6982e-02, -2.0828e-01, -1.8617e-01,  1.4756e-01,  3.1794e-02,\n",
              "          1.8766e-02,  2.3047e-01,  2.3959e-02, -1.4335e-01,  3.7632e-03,\n",
              "          2.4328e-01,  2.3433e-01, -1.1429e-01,  2.2896e-01,  2.1243e-01,\n",
              "         -2.2941e-01,  3.7661e-01, -1.3921e-01, -1.2355e-01, -2.4825e-01,\n",
              "          9.9963e-01,  9.8823e-02,  5.5966e-03, -1.2558e-02, -9.7776e-02,\n",
              "          3.0302e-01,  2.2611e-01,  3.5736e-02,  1.5670e-02,  8.0598e-01,\n",
              "         -3.3175e-01,  1.6029e-01, -3.4998e-03,  2.0949e-01, -4.1358e-02,\n",
              "          2.8093e-01, -1.7232e-01,  3.8742e-01, -1.7771e-01,  1.5117e-01,\n",
              "          4.6701e-02,  2.9139e-02,  1.9726e-01,  1.0469e-01, -1.2073e-02,\n",
              "          3.4587e-01,  2.8704e-01, -4.1617e-01,  2.2129e-01, -3.3567e-01,\n",
              "         -3.4663e-03,  7.5892e-02, -1.4306e-01, -3.9148e-01, -1.6256e-01,\n",
              "         -2.7772e-01, -2.6296e-02,  1.0155e-01, -1.7857e-01,  1.7704e-01,\n",
              "          1.0671e-01, -3.6381e-01,  2.5996e-01,  2.5362e-01, -5.1172e-01,\n",
              "          3.2910e-01, -1.1418e-01,  2.6816e-01, -2.9628e-01,  3.1398e-01,\n",
              "         -3.1072e-02, -3.5010e-02, -1.4321e-01, -1.8373e-01,  5.6814e-01,\n",
              "          1.8644e-01, -1.5899e-01, -4.4897e-02, -2.4211e-01,  4.2736e-01,\n",
              "          1.3318e-01, -3.4743e-01,  1.2538e-01, -9.9928e-01,  2.7119e-01,\n",
              "          3.0009e-01, -4.9801e-02,  8.2877e-02,  6.3108e-02,  2.5079e-01,\n",
              "          2.6044e-01, -1.4219e-01, -9.8045e-02, -2.5575e-02,  1.9371e-01,\n",
              "          3.9792e-02,  7.4347e-02,  1.4910e-01, -2.7433e-01, -2.0473e-01,\n",
              "         -4.5516e-02, -1.1493e-01,  1.6127e-01,  3.5807e-01,  1.0103e-01,\n",
              "          1.2408e-01, -3.2263e-01,  7.0442e-02, -2.9007e-01,  1.0729e-01,\n",
              "          1.6830e-01, -4.3783e-02, -1.0638e-01, -2.0003e-01, -9.0496e-02,\n",
              "         -4.4253e-02,  2.7828e-01, -4.4878e-01,  1.9624e-01,  2.8599e-01,\n",
              "         -8.9877e-02,  1.7655e-01, -3.7499e-01,  3.5527e-01, -1.0775e-01,\n",
              "          2.6023e-01, -5.0311e-01,  8.0214e-03, -5.5031e-01, -2.5597e-01,\n",
              "          2.1818e-01,  4.5995e-01,  1.1229e-01,  9.6569e-02, -1.1964e-01,\n",
              "          3.3626e-02, -4.3433e-02,  5.6582e-02,  3.0470e-01, -7.0096e-03,\n",
              "          6.5283e-02, -4.2473e-01,  1.9404e-01, -3.1680e-01, -1.5671e-01,\n",
              "         -8.3876e-01, -4.2067e-02,  8.6400e-02,  2.0223e-01,  2.5439e-01,\n",
              "         -3.0091e-01, -3.9616e-02, -3.0830e-01, -2.6031e-01, -9.7901e-02,\n",
              "         -2.0636e-03,  2.5297e-01,  6.1427e-02,  3.7232e-01, -5.0524e-01,\n",
              "         -2.9987e-01,  7.8743e-01, -2.7767e-01,  2.8336e-02,  1.0701e-01,\n",
              "          3.4554e-01,  7.3512e-01,  3.0925e-03,  1.4967e-01,  5.2369e-02,\n",
              "         -1.6342e-01,  2.3004e-01,  1.4108e-01]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vocab을 새롭게 추가했다면, 반드시 model의 embedding layer 사이즈를 늘려주세요!"
      ],
      "metadata": {
        "id": "cQX5yUS01omQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_input_embeddings())\n",
        "model.resize_token_embeddings(tokenizer.vocab_size + added_token_num)\n",
        "print(model.get_input_embeddings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TFaM6Ro2Bdb",
        "outputId": "7d562952-0f9d-4547-8c42-8df9dc07ace0"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(119547, 768, padding_idx=0)\n",
            "Embedding(119552, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [CLS] 토큰을 활용해 문장의 유사도를 측정할 수 있다."
      ],
      "metadata": {
        "id": "CzJYeqFf2Tf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = tokenizer(\"오늘 하루 어떻게 보냈나요?\", return_tensors=\"pt\")\n",
        "sent2 = tokenizer(\"오늘은 어떤 하루를 보내셨나요?\", return_tensors=\"pt\")\n",
        "sent3 = tokenizer(\"이순신은 조선 중기의 무신이다.\", return_tensors=\"pt\")\n",
        "sent4 = tokenizer(\"깟뻬뜨랑 리뿔이 뜨럽거 므리커럭이 케쇽 냐왜쇼 우뤼갸 쳥쇼섀료다혀뚜여\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "IAtElx262kpU"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**sent1)\n",
        "sent_1_pooler_output = outputs.pooler_output\n",
        "\n",
        "outputs = model(**sent2)\n",
        "sent_2_pooler_output = outputs.pooler_output\n",
        "\n",
        "outputs = model(**sent3)\n",
        "sent_3_pooler_output = outputs.pooler_output\n",
        "\n",
        "outputs = model(**sent4)\n",
        "sent_4_pooler_output = outputs.pooler_output"
      ],
      "metadata": {
        "id": "S9uL9XL82-Fj"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "print(cos(sent_1_pooler_output, sent_2_pooler_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCfaVyex3Xji",
        "outputId": "336ab76a-86b8-4338-bf5f-c16455278103"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9757], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cos(sent_2_pooler_output, sent_3_pooler_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cABt_8HF3ttr",
        "outputId": "7da01edc-7f41-4e04-94cc-dd7b63f799f8"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6075], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cos(sent_3_pooler_output, sent_4_pooler_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kr2W_Fz3x-A",
        "outputId": "2ead802b-1347-4c70-f702-50e7ff33b050"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5997], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cos(sent_1_pooler_output, sent_4_pooler_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4amFLahR31i7",
        "outputId": "9cf074cc-3c4a-430c-964e-69426f828d29"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9258], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    }
  ]
}